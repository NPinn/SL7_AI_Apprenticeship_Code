{"metadata": {"anaconda-cloud": {}, "kernelspec": {"display_name": "Python 3", "language": "python", "name": "python3"}, "language_info": {"codemirror_mode": {"name": "ipython", "version": 3}, "file_extension": ".py", "mimetype": "text/x-python", "name": "python", "nbconvert_exporter": "python", "pygments_lexer": "ipython3", "version": "3.7"}}, "nbformat": 4, "nbformat_minor": 1, "cells": [{"cell_type": "markdown", "metadata": {"slideshow": {"slide_type": "slide"}}, "source": ["# K-Means Clustering"]}, {"cell_type": "markdown", "metadata": {"slideshow": {"slide_type": "slide"}}, "source": ["Let's import the packages that we will use during the practical:"]}, {"cell_type": "code", "execution_count": null, "metadata": {"slideshow": {"slide_type": "slide"}}, "outputs": [], "source": ["import numpy as np\n", "import pandas as pd\n", "import matplotlib.pyplot as plt\n", "%matplotlib inline\n", "import seaborn as sns"]}, {"cell_type": "markdown", "metadata": {"slideshow": {"slide_type": "slide"}}, "source": ["##  The dataset"]}, {"cell_type": "markdown", "metadata": {"slideshow": {"slide_type": "slide"}}, "source": ["As the first step, we need to import data from `retail_dataset.csv` using `read_csv()` function from `pandas` (`pd`). We also want to define the column that we are going to use as the row labels of the dataframe: *CustomerID*. Once loaded, we can apply `head()` function to preview the first five rows of our dataframe. "]}, {"cell_type": "code", "execution_count": null, "metadata": {"slideshow": {"slide_type": "slide"}}, "outputs": [], "source": ["# Import the data from the retail_dataset.csv\n", "\n", "customers_data = pd.read_csv('data/retail_dataset.csv', index_col='CustomerID')\n", "customers_data.head()"]}, {"cell_type": "markdown", "metadata": {"slideshow": {"slide_type": "slide"}}, "source": ["We will start by looking specifically at the numerical features. Below we list non-binary features and separate them into a dataframe called `customers`:"]}, {"cell_type": "code", "execution_count": null, "metadata": {"slideshow": {"slide_type": "slide"}}, "outputs": [], "source": ["non_binary_cols = [\n", "    'balance', 'max_spent', 'mean_spent', \n", "    'min_spent', 'n_orders','total_items', \n", "    'total_refunded', 'total_spent']\n", "\n", "customers = customers_data[non_binary_cols]\n", "customers.head()"]}, {"cell_type": "markdown", "metadata": {"slideshow": {"slide_type": "slide"}}, "source": ["## Clustering with K-Means\n", "\n", "K-Means clustering is a method for finding clusters and cluster centroids (the centre point of a cluster) in a set of points. The K-Means algorithm is quite simple and alternates between two steps:\n", "\n", "1. For each centroid, identify the subset of training points that are closer to it than to any other centroid.\n", "2. Update the location of the centroid to match the points related to it.\n", "\n", "These two steps are repeated until the centroids no longer move (significantly) or the assignments no longer change. Then a new point $x$ can be assigned to the nearest cluster.\n", "\n", "### Run K-Means with two features\n", "\n", "Isolate the features `mean_spent` and `max_spent`, then run the K-Means algorithm on the resulting dataset using $k=2$ and visualise the result. You will need:\n", "\n", "* to create an instance of `KMeans` with 2 clusters,\n", "* fit this to the isolated features (via the `.fit` method),\n", "* look how it is doing by showing the assignment predicted (via the `.predict` method).\n", "\n", "This is the standard `sklearn` workflow for most of the algorithms."]}, {"cell_type": "code", "execution_count": null, "metadata": {"slideshow": {"slide_type": "slide"}}, "outputs": [], "source": ["from sklearn.cluster import KMeans\n", "\n", "cust2  = customers[['mean_spent', 'max_spent']]\n", "# Apply K-Means with 2 clusters using a subset of features \n", "# (mean_spent and max_spent)\n", "\n", "kmeans = KMeans(n_clusters=2)\n", "kmeans.fit(cust2)\n"]}, {"cell_type": "code", "execution_count": null, "metadata": {"slideshow": {"slide_type": "slide"}}, "outputs": [], "source": ["#store the cluster assignment\n", "cluster_assignment = kmeans.predict(cust2)"]}, {"cell_type": "markdown", "metadata": {"slideshow": {"slide_type": "slide"}}, "source": ["Let's introduce a simple function to better visualise what is going on:"]}, {"cell_type": "code", "execution_count": null, "metadata": {"slideshow": {"slide_type": "slide"}}, "outputs": [], "source": ["# This function generates a pairplot enhanced with the result of K-Means\n", "def pairplot_cluster(df, cols, cluster_assignment):\n", "    \"\"\"\n", "    Input\n", "        df, dataframe that contains the data to plot\n", "        cols, columns to consider for the plot\n", "        cluster_assignments, cluster asignment returned \n", "        by the clustering algorithm\n", "    \"\"\"\n", "    # seaborn will color the samples according to the column cluster\n", "    df_tmp = df.copy() # create a copy so we don't modify the original dataframe\n", "    df_tmp['cluster'] = cluster_assignment \n", "    sns.pairplot(df_tmp, vars=cols, hue='cluster')"]}, {"cell_type": "markdown", "metadata": {"slideshow": {"slide_type": "slide"}}, "source": ["Let's use the method now to see how we did previously (ignore the warnings if anything comes up):"]}, {"cell_type": "code", "execution_count": null, "metadata": {"slideshow": {"slide_type": "slide"}}, "outputs": [], "source": ["# Visualise the clusters using pairplot_cluster()\n", "pairplot_cluster(customers, ['mean_spent', 'max_spent'], cluster_assignment)\n"]}, {"cell_type": "markdown", "metadata": {"slideshow": {"slide_type": "slide"}}, "source": ["#### What can you observe?\n", "\n", "* The separation between the two clusters is \"clean\" (the two clusters can be separated with a line).\n", "* One cluster contains customers with low spendings, the other one with high spendings."]}, {"cell_type": "markdown", "metadata": {"slideshow": {"slide_type": "slide"}}, "source": ["### Run K-Means with all the features\n", "Run K-Means using all the features available and visualise the result in the subspace of `mean_spent` and `max_spent`."]}, {"cell_type": "code", "execution_count": null, "metadata": {"slideshow": {"slide_type": "slide"}}, "outputs": [], "source": ["# Apply K-Means with 2 clusters using all features\n", "kmeans = KMeans(n_clusters=2)\n", "kmeans.fit(customers)\n", "cluster_assignment = kmeans.predict(customers)\n"]}, {"cell_type": "markdown", "metadata": {"slideshow": {"slide_type": "slide"}}, "source": ["Visualise the cluster assignment using the same subset of variables as before. What has changed?"]}, {"cell_type": "code", "execution_count": null, "metadata": {"slideshow": {"slide_type": "slide"}}, "outputs": [], "source": ["# Visualise the clusters using pairplot_cluster()\n", "pairplot_cluster(customers, ['mean_spent', 'max_spent'], cluster_assignment)\n"]}, {"cell_type": "markdown", "metadata": {"slideshow": {"slide_type": "slide"}}, "source": ["***Question***: Why can't the clusters be separated with a line as before?"]}, {"cell_type": "markdown", "metadata": {"slideshow": {"slide_type": "slide"}}, "source": ["### Compare expenditure between clusters\n", "\n", "Select the features `mean_spent` and `max_spent` and compare the two clusters obtained above using them."]}, {"cell_type": "code", "execution_count": null, "metadata": {"slideshow": {"slide_type": "slide"}}, "outputs": [], "source": ["# Compare expenditure between clusters\n", "features = ['mean_spent', 'max_spent']\n", "\n", "# create a dataframe corresponding to the case\n", "# cluster_assignment == 0\n", "cluster1_df = pd.DataFrame(data=customers[cluster_assignment == 0], \n", "                           columns=customers.columns)[features]\n", "\n", "cluster1_desc = cluster1_df.describe()\n"]}, {"cell_type": "code", "execution_count": null, "metadata": {"slideshow": {"slide_type": "slide"}}, "outputs": [], "source": ["# then with cluster_assignment == 1\n", "cluster2_df = pd.DataFrame(data=customers[cluster_assignment == 1], \n", "                           columns=customers.columns)[features]\n", "\n", "cluster2_desc = cluster2_df.describe()\n"]}, {"cell_type": "code", "execution_count": null, "metadata": {"slideshow": {"slide_type": "slide"}}, "outputs": [], "source": ["# Join both\n", "compare_df = cluster1_desc.join(cluster2_desc, lsuffix='_cluster1', rsuffix='_cluster2')\n", "compare_df\n"]}, {"cell_type": "markdown", "metadata": {"slideshow": {"slide_type": "slide"}}, "source": ["### Look at the centroids\n", "\n", "Look at the centroids of the clusters by calling `kmeans.cluster_centers_` and check the values of the centroids for the features `mean_spent`, `max_spent`. You will need to create a new dataframe where the data is simply `kmeans.cluster_centers_`."]}, {"cell_type": "code", "execution_count": null, "metadata": {"slideshow": {"slide_type": "slide"}}, "outputs": [], "source": ["# Get the centroids and display them\n", "centers_df = pd.DataFrame(data=kmeans.cluster_centers_, columns=customers.columns)\n", "print(centers_df[features])\n"]}, {"cell_type": "markdown", "metadata": {"slideshow": {"slide_type": "slide"}}, "source": ["### Compare mean expediture with box plot\n", "\n", "Compare the distribution of the feature `mean_spent` in the two clusters using a box plot. You will need:\n", "\n", "* `sns.boxplot` (seaborn's boxplot)"]}, {"cell_type": "code", "execution_count": null, "metadata": {"slideshow": {"slide_type": "slide"}}, "outputs": [], "source": ["# Compare mean expediture with box plot\n", "\n", "#plt.figure(figsize = (10,6))\n", "sns.boxplot(data=[cluster1_df.mean_spent, cluster2_df.mean_spent])\n", "plt.show()\n"]}, {"cell_type": "markdown", "metadata": {"slideshow": {"slide_type": "slide"}}, "source": ["Does this seem to make sense? How can you interpret the plots?"]}, {"cell_type": "markdown", "metadata": {"slideshow": {"slide_type": "slide"}}, "source": ["### Look at the inertia\n", "Inertia measures the internal coherence of clusters. You can look at the inertia easily by calling ``kmeans.inertia_``:"]}, {"cell_type": "code", "execution_count": null, "metadata": {"slideshow": {"slide_type": "slide"}}, "outputs": [], "source": ["# Look at the inertia\n", "print('Inertia: {0:.2f}'.format(kmeans.inertia_))\n"]}, {"cell_type": "markdown", "metadata": {"slideshow": {"slide_type": "slide"}}, "source": ["The value of inertia on its own does not say much as it is not normalized. However, it can be used for selecting a suitable number of clusters as part of the elbow method.\n", "\n", "In elbow method, we first calculate inertia for clusterings with different numbers of clusters. We then choose the number with the largest change in rate of decline as explained in the lecture."]}, {"cell_type": "markdown", "metadata": {"slideshow": {"slide_type": "slide"}}, "source": ["### Compute the silhouette score\n", "Compute the silhouette score of the clusters resulting from the application of K-Means.\n", "\n", "The score represents how similar a sample is to the samples in its own cluster compared to samples in other clusters. The best value is 1, while the worst value is -1. Values close to 0 suggest overlapping clusters. Negative values occur when a sample is assigned to the wrong cluster (a different cluster is more similar).\n", "\n", "`sklearn` provides the function `silhouette_score`, which you can call and display."]}, {"cell_type": "code", "execution_count": null, "metadata": {"slideshow": {"slide_type": "slide"}}, "outputs": [], "source": ["from sklearn.metrics import silhouette_score\n", "\n", "# Computing the silhouette score\n", "print('Silhouette score: {0:.2f}'.format(silhouette_score(customers, cluster_assignment)))\n"]}, {"cell_type": "markdown", "metadata": {"slideshow": {"slide_type": "slide"}}, "source": ["This silhouette score is reasonably high, which we can interpret by saying that the corresponding clusters are quite compact."]}, {"cell_type": "markdown", "metadata": {"slideshow": {"slide_type": "slide"}}, "source": ["### Finding the optimal number of clusters\n", "\n", "Try plotting the inertia and silhouette score for different numbers of clusters (e.g. between 1 and 20)\n", "\n", "Note that silhouette score can only be calculated for two or more clusters."]}, {"cell_type": "code", "execution_count": null, "metadata": {"slideshow": {"slide_type": "slide"}}, "outputs": [], "source": ["k_vals = [i + 1 for i in range(20)]\n", "silhouette_scores = []\n", "inertias = []\n", "\n", "# calculate the scores\n", "for k in k_vals:\n", "    kmeans = KMeans(n_clusters=k)\n", "    kmeans.fit(customers)\n", "    cluster_assignment = kmeans.labels_\n", "    if k>1:\n", "        silhouette_scores.append(silhouette_score(customers, cluster_assignment))\n", "    else:\n", "        silhouette_scores.append(None)\n", "    inertias.append(kmeans.inertia_)\n", "    \n", "print(f'Silhoutte scores: {silhouette_scores} \\n\\n Intertias {inertias}')\n"]}, {"cell_type": "code", "execution_count": null, "metadata": {"slideshow": {"slide_type": "slide"}}, "outputs": [], "source": ["fig, ax1 = plt.subplots()\n", "\n", "color = 'tab:orange'\n", "ax1.set_xlabel('k')\n", "ax1.set_ylabel('inertias', color=color)\n", "ax1.plot(k_vals, inertias, color=color)\n", "ax1.tick_params(axis='y', labelcolor=color)\n", "\n", "ax1.set_xlim(0,20)\n", "ax1.set_xticks(k_vals)\n", "ax1.set_ylim(0,26000)\n", "ax1.grid(visible=True, axis='x', linestyle='--')\n", "\n", "ax2 = ax1.twinx()  # instantiate a second axes that shares the same x-axis\n", "\n", "color = 'tab:blue'\n", "ax2.set_ylabel('silhouette score', color=color) #  we already handled the x-label with ax1\n", "ax2.plot(k_vals, silhouette_scores, color=color)\n", "ax2.tick_params(axis='y', labelcolor=color)\n", "fig.tight_layout()  # otherwise the right y-label is slightly clipped\n", "plt.show()"]}]}