{"cells": [{"cell_type": "markdown", "metadata": {"slideshow": {"slide_type": "slide"}}, "source": ["# Discriminative Classifiers: K-Nearest Neighbours\n", "\n", "In this practical, we will first manually implement k-nearest neighbours. We will explore how the algorithm constructs decision boundaries and how it classifies data. We will visualise these boundaries for our own implementation, before using `sklearn` implentations to compare and contrast with our own.\n", "\n", "Then, we will move to using `sklearn` for a more traditional data science task, using a real dataset."]}, {"cell_type": "markdown", "metadata": {"slideshow": {"slide_type": "slide"}}, "source": ["# Implementing KNN\n", "\n", "Recall that the KNN algorithm relies on the concept of distance between two items in order to quantify how similar they are. Input data is represented as an array of features, which locates each item within a vector space. We will use data with two dimensions, longitude and latitude, which will make it easy to visualise.\n", "\n", "We will need four functions:\n", "\n", "1. `euclidean_distance(p1, p2)` - given a pair of (x,y) coordinates, calculate how close they are using Euclidean distance: $$ \\sqrt{(x_2-x_1)^2+(y_2-y_1)^2} $$\n", "2. `manhattan_distance(p1, p2)` - calculate $$ | x_1 - x_2 | + | y_1 - y_2 | $$\n", "3. `get_neighbours(new_point, known_points, distance_function)` - given a single coordinate, calculate how close it is to all other points using the provided distance function\n", "4. `classify(neighbours_list, k)` - given a list of points with their distances and their class label, determine which class is most common in the `k` nearest neighbours\n", "\n", "The classification process will work as follows:\n", "\n", "1. For a new point with no class label, get the distance from it to every known point\n", "2. From that list of distances, take the `k` nearest ones\n", "3. From that subset, find out which class is the most common and use it to label the new point\n", "\n", "Below are templates for the functions, which you will complete."]}, {"cell_type": "markdown", "metadata": {"slideshow": {"slide_type": "slide"}}, "source": ["## The distance functions\n", "\n", "Complete the two functions below using the docstring as a guide.\n", "\n", "(Note: to calculate the absolute value for Manhattan distance, use the `abs()` function.)"]}, {"cell_type": "code", "execution_count": 1, "metadata": {"slideshow": {"slide_type": "slide"}}, "outputs": [], "source": ["from math import sqrt  # For calculating square root\n", "\n", "\n", "def euclidean_distance(point1, point2):\n", "    \"\"\"\n", "    Inputs:\n", "        point1 : a tuple of (lon, lat) coordinates\n", "        point2 : a tuple of (lon, lat) coordinates\n", "\n", "    Returns:\n", "        distance : a float, the distance between the points\n", "    \"\"\"\n", "\n", "    # Your code here...\n", "\n", "    distance = sqrt((point1[0] - point2[0]) ** 2 + (point1[1] - point2[1]) ** 2)\n", "\n", "    return distance\n"]}, {"cell_type": "code", "execution_count": 2, "metadata": {"slideshow": {"slide_type": "slide"}}, "outputs": [], "source": ["def manhattan_distance(point1, point2):\n", "    \"\"\"\n", "    Inputs:\n", "        point1 : a tuple of (lon, lat) coordinates\n", "        point2 : a tuple of (lon, lat) coordinates\n", "\n", "    Returns:\n", "        distance : a float, the distance between the points\n", "    \"\"\"\n", "\n", "    # Your code here...\n", "\n", "    distance = abs(point1[0] - point2[0]) + abs(point1[1] - point2[1])\n", "\n", "    return distance\n", "\n"]}, {"cell_type": "markdown", "metadata": {"slideshow": {"slide_type": "slide"}}, "source": ["## Testing the `distance` functions\n", "\n", "Run the cell below to test your functions are working as expected."]}, {"cell_type": "code", "execution_count": 3, "metadata": {"slideshow": {"slide_type": "slide"}}, "outputs": [], "source": ["assert euclidean_distance((0, 0), (0, 0)) == 0\n", "assert euclidean_distance((0, 0), (-1, 0)) == 1\n", "assert euclidean_distance((0, 0), (2, 0)) == 2\n", "assert euclidean_distance((0, 0), (1, 1)) == 1.4142135623730951\n", "assert euclidean_distance((1233, 376.4), (-213.2, 0.03)) == 1494.372382272906\n", "\n", "assert manhattan_distance((0, 0), (0, 0)) == 0\n", "assert manhattan_distance((0, 0), (-1, 0)) == 1\n", "assert manhattan_distance((0, 0), (2, 0)) == 2\n", "assert manhattan_distance((0, 0), (1, 1)) == 2\n", "assert manhattan_distance((1233, 376.4), (-213.2, 0.03)) == 1822.5700000000002\n", "\n", "print(\"All good!\")"]}, {"cell_type": "markdown", "metadata": {"slideshow": {"slide_type": "slide"}}, "source": ["## The `get_neighbours` function\n", "\n", "This should loop through a list of labeled points and calculate the distance between each one and a new unlabeled point, using your `distance` function.\n", "\n", "(Note: the returned list should be sorted, such that the first item is the nearest and so on. Use `sorted()` on a list. To sort them by the third item in each sub-item, use `sorted(your_list, key=itemgetter(2))` - remember that Python starts counting at 0, not 1.)"]}, {"cell_type": "code", "execution_count": 4, "metadata": {"slideshow": {"slide_type": "slide"}}, "outputs": [], "source": ["from operator import (\n", "    itemgetter,\n", ")  # For sorting lists by particular items inside sub-items\n", "\n", "\n", "\n", "def get_neighbours(new_point, known_points, distance_function):\n", "    \"\"\"\n", "    Inputs:\n", "        new_point : a tuple of (lon, lat) coordinates\n", "        known_points : a list of tuples of (lon, lat, label)\n", "        distance_function : a function to calculate distance\n", "    Returns:\n", "        neighbours : a sorted list of tuples with ((lon, lat), label, distance)\n", "    \"\"\"\n", "\n", "    # Your code here...\n", "\n", "    neighbours = []\n", "\n", "    for lon, lat, label in known_points:\n", "        d = distance_function(new_point, (lon, lat))\n", "\n", "        neighbours.append(((lon, lat), label, d))\n", "\n", "\n", "    neighbours = sorted(neighbours, key=itemgetter(2))\n", "\n", "    return neighbours\n"]}, {"cell_type": "markdown", "metadata": {"slideshow": {"slide_type": "slide"}}, "source": ["## Testing the `distance` function\n", "\n", "Run the cell below to test your function is working as expected."]}, {"cell_type": "code", "execution_count": 5, "metadata": {"slideshow": {"slide_type": "slide"}}, "outputs": [], "source": ["known = [(0, 0, \"A\"), (1, 1, \"A\"), (3, 4, \"B\"), (5, 4, \"B\"), (1.5, 1.5, \"C\")]\n", "new = (2, 2)\n", "\n", "assert get_neighbours(new, known, euclidean_distance) == [\n", "    ((1.5, 1.5), \"C\", 0.7071067811865476),\n", "    ((1, 1), \"A\", 1.4142135623730951),\n", "    ((3, 4), \"B\", 2.23606797749979),\n", "    ((0, 0), \"A\", 2.8284271247461903),\n", "    ((5, 4), \"B\", 3.605551275463989),\n", "]\n", "\n", "assert get_neighbours(new, known, manhattan_distance) == [\n", "    ((1.5, 1.5), \"C\", 1.0),\n", "    ((1, 1), \"A\", 2),\n", "    ((3, 4), \"B\", 3),\n", "    ((0, 0), \"A\", 4),\n", "    ((5, 4), \"B\", 5),\n", "]\n", "\n", "print(\"All good!\")"]}, {"cell_type": "markdown", "metadata": {"slideshow": {"slide_type": "slide"}}, "source": ["## The `classify` function\n", "\n", "This function should take the output of `get_neighbours` and calculate which class is the most common in the nearest `k` items.\n", "\n", "`collections.Counter` can turn a list of items into a dictionary of item:count.\n", "\n", "`Counter(['A', 'B', 'B'])` gives you `{'A':1, 'B':2}`\n", "\n", "To get the top item, use the `.most_common()` method, which returns a sorted list of item/count pairs. The first item is the most common item."]}, {"cell_type": "code", "execution_count": 6, "metadata": {"slideshow": {"slide_type": "slide"}}, "outputs": [], "source": ["from collections import Counter\n", "\n", "some_list = list(\"AUHSUGQWURBUQWVYFVQFQFQIHIUQBF\")\n", "\n", "counts = Counter(some_list)\n", "print(f\"The counter: {counts}\\n\")\n", "\n", "top_item = counts.most_common()\n", "print(f\"Items sorted by their counts: {top_item}\\n\")\n", "print(f\"Most common item and its count: {top_item[0]}\\n\")\n", "print(f\"Most common item's name: {top_item[0][0]}\\n\")\n", "print(f\"Most common item's count: {top_item[0][1]}\")"]}, {"cell_type": "code", "execution_count": 7, "metadata": {"slideshow": {"slide_type": "slide"}}, "outputs": [], "source": ["# Complete the function below.\n", "# The first part checks to make sure k is a valid value,\n", "# based on the data the function is passed.\n", "\n", "\n", "def classify(neighbours_list, k):\n", "    \"\"\"\n", "    Inputs:\n", "        neighbours_list : a list of ((lon, lat), label, distance)\n", "        k : the number of neighbours to use for classification\n", "    Returns:\n", "        label : the most commonly observed label of the top k items in neighbours\n", "    \"\"\"\n", "    if k <= 0:\n", "        raise ValueError(\"k too low: must be > 0\")\n", "    if k > len(neighbours_list):\n", "        raise ValueError(\"k too high: must be <= the number of neighbours\")\n", "\n", "    # Your code here...\n", "    top_neighbours = neighbours_list[0:k]\n", "    top_classes = [neighbour[1] for neighbour in top_neighbours]\n", "    counts = Counter(top_classes)\n", "    top_item = counts.most_common()[0]\n", "    label = top_item[0]\n", "    return label\n"]}, {"cell_type": "markdown", "metadata": {"slideshow": {"slide_type": "slide"}}, "source": ["## Testing"]}, {"cell_type": "code", "execution_count": 8, "metadata": {"slideshow": {"slide_type": "slide"}}, "outputs": [], "source": ["known = [(0, 0, \"A\"), (1, 1, \"A\"), (3, 4, \"B\"), (5, 4, \"B\"), (1.5, 1.5, \"C\")]\n", "new = (0.5, 0.5)\n", "\n", "neighbours_euc = get_neighbours(new, known, euclidean_distance)\n", "assert classify(neighbours_euc, 3) == \"A\"\n", "\n", "neighbours_man = get_neighbours(new, known, manhattan_distance)\n", "assert classify(neighbours_man, 3) == \"A\"\n", "\n", "print(\"All good!\")"]}, {"cell_type": "markdown", "metadata": {"slideshow": {"slide_type": "slide"}}, "source": ["## Putting it all together\n", "\n", "Putting this all together, we can now do KNN classification with the following workflow.\n", "\n", "(It's not as elegant as `sklearn` but it works!)"]}, {"cell_type": "code", "execution_count": 9, "metadata": {"slideshow": {"slide_type": "slide"}}, "outputs": [], "source": ["train_data = [(1, 1, \"A\"), (1, 1.5, \"A\"), (2, 2, \"A\"), (4, 5, \"B\"), (8, 4, \"B\")]\n", "\n", "new_data = [(0.5, 0.5), (9.3, 9.0), (5.1, 5.6)]\n", "\n", "for point in new_data:\n", "    neighbours = get_neighbours(point, train_data, euclidean_distance)\n", "    label = classify(neighbours, k=3)\n", "\n", "    print(f\"Item: {point} Prediction: {label}\")"]}, {"cell_type": "markdown", "metadata": {"slideshow": {"slide_type": "slide"}}, "source": ["## KNN: assigning towns to regions\n", "\n", "Imagine you are a government official, in charge of assigning new towns to a region.\n", "\n", "This job was easy until someone lost all the boundary maps. Now, nobody knows what the geographical properties of each region actually are.\n", "\n", "Fortunately, you **do** know which region all the existing towns are in, as well as the coordinates of all those towns.\n", "\n", "You decide that the best approach is assign new towns to a region based on which other towns it is nearest to."]}, {"cell_type": "code", "execution_count": 10, "metadata": {"slideshow": {"slide_type": "slide"}}, "outputs": [], "source": ["import pandas as pd\n", "\n", "data = pd.read_csv(\"data/uk-towns-sample.csv\")\n", "\n", "train_data = data[data[\"kind\"] == \"Train\"]\n", "test_data = data[data[\"kind\"] == \"Test\"]\n", "\n", "train_data.head()"]}, {"cell_type": "code", "execution_count": 11, "metadata": {"slideshow": {"slide_type": "slide"}}, "outputs": [], "source": ["# Get the data into the expected format for our functions\n", "\n", "train_data = list(\n", "    zip(train_data.lon.tolist(), train_data.lat.tolist(), train_data.region.tolist())\n", ")\n", "test_data = list(\n", "    zip(test_data.lon.tolist(), test_data.lat.tolist(), test_data.region.tolist())\n", ")"]}, {"cell_type": "markdown", "metadata": {"slideshow": {"slide_type": "slide"}}, "source": ["With your KNN functions, write a loop that goes through the first 3 items of `test_data` and predicts a region for them.\n", "\n", "Get predictions for Euclidean distance, at `k=3` and `k=300`.\n", "\n", "What do you observe? What happens when `k` is large? Why do you think that is?"]}, {"cell_type": "code", "execution_count": 12, "metadata": {"slideshow": {"slide_type": "slide"}}, "outputs": [], "source": ["# Your code here...\n", "\n", "for lon, lat, region in test_data[0:3]:\n", "    point = (lon, lat)\n", "    neighbours = get_neighbours(point, train_data, euclidean_distance)\n", "    label_3 = classify(neighbours, k=3)\n", "    label_300 = classify(neighbours, k=300)\n", "\n", "    print(f\"Expected region: {region}\")\n", "    print(f\"\\t Prediction \\n\\t k=3: {label_3} \\n\\t k=300 {label_300}\\n\")\n", "\n", "# Accuracy is perfect at k=3 but at k=300 it is zero. This is likely because using too many neighbours simply selects the region containing the most towns.\n", "\n"]}, {"cell_type": "markdown", "metadata": {"slideshow": {"slide_type": "slide"}}, "source": ["## Evaluating the predictions\n", "\n", "The cell below will use the test data to evaluate performance at different `k` values. As you can see, setting `k` too high or too low hurts performance on unseen data.\n", "\n", "Note that our implementation takes around 1 second to run all these predictions."]}, {"cell_type": "code", "execution_count": null, "metadata": {"scrolled": true, "slideshow": {"slide_type": "slide"}}, "outputs": [], "source": ["%%time\n", "\n", "from sklearn.metrics import f1_score\n", "\n", "for k in [1, 3, 5, 10, 20, 100, 300]:\n", "    predictions = []\n", "    expected = []\n", "\n", "    for lon, lat, region in test_data:\n", "        point = (lon, lat)\n", "\n", "        neighbours = get_neighbours(point, train_data, euclidean_distance)\n", "        label = classify(neighbours, k=k)\n", "\n", "        predictions.append(label)\n", "        expected.append(region)\n", "\n", "    print(\n", "        f'F1 score for k={k}\\t: {f1_score(expected, predictions, zero_division=0, average=\"weighted\"):.3f}'\n", "    )"]}, {"cell_type": "markdown", "metadata": {"slideshow": {"slide_type": "slide"}}, "source": ["## Recreating the map\n", "\n", "How could you use the data and the model to create a new map, showing the regional boundaries? How would it compare to the \"true\" map?"]}, {"cell_type": "code", "execution_count": null, "metadata": {"slideshow": {"slide_type": "slide"}}, "outputs": [], "source": ["# Your thoughts below...\n", "\n", "# You could classify every single lon/lat point on a map grid. This should show the structure of the boundaries.\n", "# It should look fairly similar to the original map, but the outlines of the regions are not likely to be very high resolution.\n", "\n"]}, {"cell_type": "markdown", "metadata": {"slideshow": {"slide_type": "slide"}}, "source": ["Running the cell below will do the following\n", "\n", "1. Determine the min/max lon/lat points\n", "2. Use these to create a grid of (x,y) points\n", "3. Classify all these points using the KNN model\n", "4. Colour each point according to prediction\n", "5. Plot predictions and towns\n", "\n", "(It will take maybe a minute or two, because the KNN prediction process is not optimised! But there is a little progress bar, to show you that things are happening.)"]}, {"cell_type": "code", "execution_count": null, "metadata": {"scrolled": true, "slideshow": {"slide_type": "slide"}}, "outputs": [], "source": ["from sklearn.metrics import classification_report\n", "import matplotlib.pyplot as plt\n", "from matplotlib.colors import ListedColormap\n", "import numpy as np\n", "from tqdm.notebook import tqdm\n", "\n", "colour_vals = np.linspace(0, 1, 96)\n", "np.random.seed(5)\n", "np.random.shuffle(colour_vals)\n", "cmap = plt.cm.colors.ListedColormap(plt.cm.hsv(colour_vals))\n", "\n", "\n", "def plot(k):\n", "    # Make coords for predicting\n", "    min_lon, max_lon = (\n", "        min(train_data, key=itemgetter(0))[0],\n", "        max(train_data, key=itemgetter(0))[0],\n", "    )\n", "    min_lat, max_lat = (\n", "        min(train_data, key=itemgetter(1))[1],\n", "        max(train_data, key=itemgetter(1))[1],\n", "    )\n", "\n", "    xx, yy = np.meshgrid(\n", "        np.arange(min_lon, max_lon, 0.1), np.arange(min_lat, max_lat, 0.1)\n", "    )\n", "\n", "    # Do the predictions\n", "    grid_predictions = []\n", "    for point in tqdm(zip(xx.flatten(), yy.flatten()), total=len(xx.flatten())):\n", "        neighbours = get_neighbours(point, train_data, euclidean_distance)\n", "        label = classify(neighbours, k=k)\n", "        grid_predictions.append(label)\n", "    grid_predictions = np.array(grid_predictions).reshape(xx.shape)\n", "\n", "    # Need to be able to convert between text and numerical labels, to plot properly\n", "    p_to_i = {p: i for i, p in enumerate(set([i[2] for i in train_data]))}\n", "    i_to_p = {i: p for i, p in enumerate(set([i[2] for i in train_data]))}\n", "\n", "    # Plot each grid prediction\n", "    plt.pcolormesh(\n", "        xx,\n", "        yy,\n", "        np.array([p_to_i[p] for p in grid_predictions.flatten()]).reshape(xx.shape),\n", "        cmap=cmap,\n", "        shading=\"auto\",\n", "    )\n", "\n", "    # Plot the towns, coloured by region\n", "    x_vals = [i[0] for i in train_data]\n", "    y_vals = [i[1] for i in train_data]\n", "    colors = [p_to_i[i[2]] for i in train_data]\n", "    plt.scatter(x_vals, y_vals, c=colors, cmap=cmap, edgecolor=\"k\", s=30)\n", "    plt.xlim(xx.min(), xx.max())\n", "    plt.ylim(yy.min(), yy.max())\n", "    plt.title(f\"k={k}\")\n", "\n", "    # Output a classification report\n", "\n", "\n", "f, a = plt.subplots(1, 3, figsize=(36, 18))\n", "\n", "for i, k in enumerate([5, 10, 20]):\n", "    plt.sca(a[i])\n", "    plot(k)"]}, {"cell_type": "markdown", "metadata": {"slideshow": {"slide_type": "slide"}}, "source": ["## Interpreting the boundaries\n", "\n", "In the three plots, we used a `k` of 3, 10 and 20. What do you observe in terms of the decision boundaries?\n", "\n", "What problems do you anticipate in terms of using this as a map of the country's regional boundaries?"]}, {"cell_type": "code", "execution_count": null, "metadata": {"slideshow": {"slide_type": "slide"}}, "outputs": [], "source": ["# Your thoughts below...\n", "\n", "# When k is large, a lot of the points are misclassified. You can tell this from the dot colour not matching the area colour.\n", "# You can see a lot of misclassified items where boundaries meet, as k gets bigger. Regions in Northern Ireland are especially poorly delineated.\n", "# This would make a decent map if it were able to tell the difference between land and sea! You can see the layout of the UK in the dots, but the model has no conception of where it is possible for towns to go.\n", "# One way around this would be to only generate predictions for coordinates we know are on land.\n", "\n"]}, {"cell_type": "markdown", "metadata": {"slideshow": {"slide_type": "slide"}}, "source": ["# KNN: sklearn\n", "\n", "Now let's compare our implementation to that in `sklearn`. Run the cell below. You'll see it only takes 100ms, compared to 1s for ours!"]}, {"cell_type": "code", "execution_count": null, "metadata": {"slideshow": {"slide_type": "slide"}}, "outputs": [], "source": ["%%time\n", "\n", "from sklearn.neighbors import KNeighborsClassifier\n", "\n", "data = pd.read_csv(\"data/uk-towns-sample.csv\")\n", "\n", "train_data = data[data.kind == \"Train\"]\n", "test_data = data[data.kind == \"Test\"]\n", "\n", "for our_score, k in zip(\n", "    [0.898, 0.912, 0.891, 0.846, 0.772, 0.382, 0.095], [1, 3, 5, 10, 20, 100, 300]\n", "):\n", "    knn = KNeighborsClassifier(n_neighbors=k)\n", "\n", "    knn.fit(train_data[[\"lon\", \"lat\"]], train_data[\"region\"])\n", "    sklearn_score = knn.score(test_data[[\"lon\", \"lat\"]], test_data[\"region\"])\n", "\n", "    print(f\"k={k}\")\n", "    print(f\"sklearn F1 score: {sklearn_score:.3f}\")\n", "    print(f\"Our F1 score: {our_score}\")\n", "    if our_score - sklearn_score > 0:\n", "        print(f\"Ours was better by {our_score - sklearn_score:.3f}\\n\\n\")\n", "    else:\n", "        print(f\"Sklearn was better by {our_score - sklearn_score:.3f}\\n\\n\")"]}, {"cell_type": "markdown", "metadata": {"slideshow": {"slide_type": "slide"}}, "source": ["# Conclusion\n", "\n", "In this practical, you implemented and explored supervised algorithms for discriminative classification. You implemented k-nearest neighbours yourself, but also used `sklearn`'s (much faster) version of it.\n", "\n", "If you want to extend the work here, you could explore how the different distance measures impacts KNN performance - can you generate a better boundary map?"]}], "metadata": {"kernelspec": {"display_name": "Python 3 (ipykernel)", "language": "python", "name": "python3"}, "language_info": {"codemirror_mode": {"name": "ipython", "version": 3}, "file_extension": ".py", "mimetype": "text/x-python", "name": "python", "nbconvert_exporter": "python", "pygments_lexer": "ipython3", "version": "3.11.9"}}, "nbformat": 4, "nbformat_minor": 4}