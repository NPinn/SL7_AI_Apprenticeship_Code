{"metadata": {"kernelspec": {"display_name": "Python 3 (ipykernel)", "language": "python", "name": "python3"}, "language_info": {"codemirror_mode": {"name": "ipython", "version": 3}, "file_extension": ".py", "mimetype": "text/x-python", "name": "python", "nbconvert_exporter": "python", "pygments_lexer": "ipython3", "version": "3.7"}}, "nbformat": 4, "nbformat_minor": 4, "cells": [{"cell_type": "markdown", "metadata": {"slideshow": {"slide_type": "slide"}}, "source": ["# Part 2: Training Convolutional Neural Networks"]}, {"cell_type": "code", "execution_count": null, "metadata": {"slideshow": {"slide_type": "slide"}}, "outputs": [], "source": ["%matplotlib inline"]}, {"cell_type": "code", "execution_count": null, "metadata": {"slideshow": {"slide_type": "slide"}}, "outputs": [], "source": ["import numpy as np\n", "import matplotlib.pyplot as plt\n", "\n", "# for elementary image manipulation\n", "\n", "# specifies the default figure size for this notebook\n", "plt.rcParams['figure.figsize'] = (10, 10)\n", "\n", "# specifies the default color map\n", "plt.rcParams['image.cmap'] = 'gray'\n", "\n", "# we'll use keras to build our networks\n", "from tensorflow import keras\n", "from keras.models import Sequential\n", "\n", "from keras.layers import Flatten, Dense, Dropout\n", "from keras.layers import Conv2D, MaxPooling2D\n", "from keras.layers import ZeroPadding2D\n", "\n", "from keras.datasets import mnist\n", "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n", "from keras.utils import to_categorical"]}, {"cell_type": "markdown", "metadata": {"slideshow": {"slide_type": "slide"}}, "source": ["## Training your own Convolutional Neural Network\n", "\n", "We're going to use the MNIST dataset, in which the goal is to categorise images in one of 10 categories. ([more information about MNIST here](http://yann.lecun.com/exdb/mnist/))\n", "\n", "If you're interested in benchmarks, have a look [here](http://rodrigob.github.io/are_we_there_yet/build/classification_datasets_results.html). \n", "\n", "### Loading the MNIST dataset\n", "\n", "Load the MNIST dataset\n", "\n", "* use `mnist.load_data()` to load the data (hopefully you have done that earlier)\n", "* separate train and test\n", "* normalise the values by 255\n", "* there are 10 categories so use `np_utils.to_categorical` to specify the output has 10 categories\n"]}, {"cell_type": "code", "execution_count": null, "metadata": {"slideshow": {"slide_type": "slide"}}, "outputs": [], "source": ["# Add your code here to load and prepare the cifar10 data\n", "# Load the data\n", "(X_train, y_train), (X_test, y_test) = keras.datasets.mnist.load_data()\n", "\n", "# Turn our images into floating point numbers\n", "X_train = X_train.astype('float32').reshape(-1, 28, 28, 1)\n", "X_test = X_test.astype('float32').reshape(-1, 28, 28, 1)\n", "\n", "# Put our input data in the range 0-1\n", "X_train /= 255\n", "X_test  /= 255\n", "\n", "# Convert class vectors to binary class matrices\n", "Y_train = to_categorical(y_train, 10)\n", "Y_test  = to_categorical(y_test, 10)\n", "\n", "# Check the shape of the data\n", "print('X_train shape:', X_train.shape)\n", "print(X_train.shape[0], 'train samples')\n", "print(X_test.shape[0], 'test samples')"]}, {"cell_type": "markdown", "metadata": {"slideshow": {"slide_type": "slide"}}, "source": ["### Building the model\n", "\n", "Let's define a model, you will use a small model so that the training is not too slow. Let's go step-by-step."]}, {"cell_type": "markdown", "metadata": {"slideshow": {"slide_type": "slide"}}, "source": ["### Implementing a convolutional model\n", "\n", "You are going to define the first convolutional layer of the network. \n", "\n", "In what follows you don't have to modify the cells but just run them making sure you understand what is being done. Do not tune the parameters as we will load pre-trained weights on the architecture!"]}, {"cell_type": "code", "execution_count": null, "metadata": {"slideshow": {"slide_type": "slide"}}, "outputs": [], "source": ["# Create the model, it's a Sequential model (stack of layers one after the other)\n", "model = Sequential()\n", "\n", "# On the very first layer, you must specify the input shape\n", "# Your first convolutional layer should have 28 3x3 filters, \n", "# the tuple (1, 1) indicates it's one pixel and symmetric.\n", "# and will use a relu activation function\n", "model.add(\n", "    Conv2D(\n", "        32,\n", "        (5, 5),\n", "        padding='same', \n", "        input_shape=(28, 28, 1),\n", "        activation='relu'\n", "    )\n", ")\n", "model.add(MaxPooling2D(pool_size=(3, 3)))\n", "model.add(Dropout(0.1))\n", "model.add(Conv2D(32, (3, 3), activation='relu'))\n", "model.add(MaxPooling2D(pool_size=(3, 3)))\n", "model.add(Dropout(0.1))\n", "model.add(Flatten())\n", "model.add(Dense(32, activation='relu'))\n", "model.add(Dropout(0.1))\n", "model.add(Dense(10, activation='softmax'))"]}, {"cell_type": "code", "execution_count": null, "metadata": {"slideshow": {"slide_type": "slide"}}, "outputs": [], "source": ["model.summary()"]}, {"cell_type": "markdown", "metadata": {"slideshow": {"slide_type": "slide"}}, "source": ["**Quiz: HOW MANY WEIGHTS IN THE NETWORK?**\n", "\n", "- How many convolution weights does the first layer contain? What about the second layer?\n", "- Are there any other weights in those layers?"]}, {"cell_type": "markdown", "metadata": {"slideshow": {"slide_type": "slide"}}, "source": ["### Define the training schedule\n", "\n", "Using the Adam optimizer, you can compile the model."]}, {"cell_type": "code", "execution_count": null, "metadata": {"slideshow": {"slide_type": "slide"}}, "outputs": [], "source": ["# Using the Adam optimizer, as before\n", "\n", "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])"]}, {"cell_type": "markdown", "metadata": {"slideshow": {"slide_type": "slide"}}, "source": ["### Image pre-processing\n", "\n", "We have to define the preprocessing for the images. Here we define:\n", "\n", "* we introduce a random horizontal and vertical shift to create more (\"perturbed\") training samples (makes the NN more robust as well)\n", "* why do you think we shouldn't flip images?\n", "\n", "This is called data or image **augmentation**. Such randomization can improve things significantly, especially if you have small datasets."]}, {"cell_type": "code", "execution_count": null, "metadata": {"slideshow": {"slide_type": "slide"}}, "outputs": [], "source": ["# Preprocessing, does both normalization and augmentation\n", "datagen = ImageDataGenerator(\n", "        rotation_range=10,                        # randomly rotate images in the range (degrees, 0 to 180)\n", "        width_shift_range=0.1,                   # randomly shift images horizontally (fraction of total width)\n", "        height_shift_range=0.1,                  # randomly shift images vertically (fraction of total height)\n", "        horizontal_flip=False,                    # randomly flip images\n", "        vertical_flip=False)                     # randomly flip images\n", "\n", "# Compute quantities required for featurewise normalization (std, mean)\n", "datagen.fit(X_train)\n", "batch_size = 128\n", "data_gen = datagen.flow(X_train, Y_train, batch_size=batch_size)"]}, {"cell_type": "markdown", "metadata": {"slideshow": {"slide_type": "slide"}}, "source": ["And you're set! You can start training and see the accuracy improve! \n", "\n", "Use the `.fit(data_gen, ...)` method, with `batch_size = 16`, 3 epochs, and add the validation data, testing the validation accuracy every epoch. "]}, {"cell_type": "code", "execution_count": null, "metadata": {"slideshow": {"slide_type": "slide"}}, "outputs": [], "source": ["nb_epoch = 2\n", "\n", "model.fit(\n", "    data_gen,\n", "    steps_per_epoch=X_train.shape[0] // batch_size,\n", "    epochs=nb_epoch,\n", "    validation_data=(X_test, Y_test),\n", "    validation_freq=1)"]}, {"cell_type": "code", "execution_count": null, "metadata": {"slideshow": {"slide_type": "slide"}}, "outputs": [], "source": ["# how did this model perform?\n", "# evaluate the model on the test data\n", "model.evaluate(X_test, Y_test)\n"]}, {"cell_type": "code", "execution_count": null, "metadata": {"slideshow": {"slide_type": "slide"}}, "outputs": [], "source": ["# check the first test image\n", "image = X_test[:1]\n", "plt.imshow(image.reshape(28, 28), cmap='gray')\n", "print(f\"Is this number {model.predict(image).argmax()}?\")\n"]}]}