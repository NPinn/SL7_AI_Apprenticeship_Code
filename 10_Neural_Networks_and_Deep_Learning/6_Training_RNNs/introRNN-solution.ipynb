{"metadata": {"kernelspec": {"display_name": "Python 3 (ipykernel)", "language": "python", "name": "python3"}, "language_info": {"codemirror_mode": {"name": "ipython", "version": 3}, "file_extension": ".py", "mimetype": "text/x-python", "name": "python", "nbconvert_exporter": "python", "pygments_lexer": "ipython3", "version": "3.7"}}, "nbformat": 4, "nbformat_minor": 2, "cells": [{"cell_type": "markdown", "metadata": {"slideshow": {"slide_type": "slide"}}, "source": ["# Neural Networks for Sequences and Time Series"]}, {"cell_type": "markdown", "metadata": {"slideshow": {"slide_type": "slide"}}, "source": ["Let's try to use recurrent neural networks for the credit card fraud detection problem that we have studied earlier. RNNs are typically better at capturing the temporal nature of the data than CNNs, and here we will be able to see how much better they are.\n", "\n", "As before, this first cell sets up the notebook.\n", "\n", "Additionally, we load the file `helpers.py` which defines:\n", "\n", "* `reshape_to_batches` \n", "* `convert_3d_to_2d` \n", "\n", "that we defined in the previous notebook."]}, {"cell_type": "code", "execution_count": null, "metadata": {"slideshow": {"slide_type": "slide"}}, "outputs": [], "source": ["import pandas as pd\n", "import numpy as np\n", "import matplotlib.pyplot as plt\n", "%matplotlib inline\n", "\n", "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n", "from sklearn.model_selection import train_test_split\n", "\n", "from sklearn.metrics import roc_curve, auc, roc_auc_score\n", "from sklearn.metrics import classification_report, accuracy_score, confusion_matrix\n", "    \n", "from sklearn.pipeline import Pipeline\n", "\n", "import keras"]}, {"cell_type": "code", "execution_count": null, "metadata": {"scrolled": true, "slideshow": {"slide_type": "slide"}}, "outputs": [], "source": ["from helpers import reshape_to_batches, convert_3d_to_2d"]}, {"cell_type": "markdown", "metadata": {"slideshow": {"slide_type": "slide"}}, "source": ["### Load the data\n", "\n", "Load the `data/creditcard.parquet` using `pd.read_parquet()` into a DataFrame called `ccfd`."]}, {"cell_type": "code", "execution_count": null, "metadata": {"slideshow": {"slide_type": "slide"}}, "outputs": [], "source": ["# Your code here...\n", "ccfd = pd.read_parquet('data/creditcard.parquet')\n", "ccfd.head()\n"]}, {"cell_type": "markdown", "metadata": {"slideshow": {"slide_type": "slide"}}, "source": ["Use `sklearn`'s `train_test_split` to create a 70/30 train test split, and ensure that the data remain ordered by time. Call the splits `X_train`, `X_test`, `y_train`, and `y_test`."]}, {"cell_type": "code", "execution_count": null, "metadata": {"slideshow": {"slide_type": "slide"}}, "outputs": [], "source": ["# Your code here...\n", "X_train, X_test, y_train, y_test = train_test_split(\n", "    ccfd.drop('Class', axis=1), \n", "    ccfd['Class'], \n", "    shuffle=False, \n", "    test_size=0.3\n", ")\n", "\n", "print(f'Shape of training features: {X_train.shape}')\n", "print(f'Shape of training labels: {y_train.shape}')\n", "print(f'Shape of test features: {X_test.shape}')\n", "print(f'Shape of test labels: {y_test.shape}')\n"]}, {"cell_type": "markdown", "metadata": {"slideshow": {"slide_type": "slide"}}, "source": ["Apply scaling preprocessing (on both the training and test set). Call the new scaled variables `X_train_s` and `X_test_s`.\n", "\n", "_Hint: you may want to use a [Pipeline](https://scikit-learn.org/stable/modules/generated/sklearn.pipeline.Pipeline.html)._"]}, {"cell_type": "code", "execution_count": null, "metadata": {"slideshow": {"slide_type": "slide"}}, "outputs": [], "source": ["# Your code here...\n", "pipeline = Pipeline([\n", "    ('scaling', StandardScaler()),\n", "])\n", "preprocessor = pipeline.fit(X_train)\n", "X_train_s = preprocessor.transform(X_train)\n", "X_test_s = preprocessor.transform(X_test)\n"]}, {"cell_type": "markdown", "metadata": {"slideshow": {"slide_type": "slide"}}, "source": ["Use the `reshape_to_batches` function with batch size 100 and apply it to the training data. Call the result `X_train_s_batch`."]}, {"cell_type": "code", "execution_count": null, "metadata": {"slideshow": {"slide_type": "slide"}}, "outputs": [], "source": ["# reshape to batches\n", "BATCH_SIZE = 100\n", "# Your code here...\n", "X_train_s_batch = reshape_to_batches(X_train_s, BATCH_SIZE)\n", "print(f'Shape after reshaping: {X_train_s_batch.shape}')\n"]}, {"cell_type": "markdown", "metadata": {"slideshow": {"slide_type": "slide"}}, "source": ["Note that the batch size is particularly important because this is the sequence size that we are going to train the RNN on. \n", "This means that any dependencies further apart than`BATCH_SIZE` **will not be taken into account**. \n", "\n", "We could in theory give only one batch with the entire sequence but that will take an excessive amount of time to train and success is not guaranteed (vanishing gradient problem). \n", "\n", "### Re-encoding the data\n", "\n", "Create a `y_binary` with two columns (0, 1) and batch `y_train`. Save the output as `y_train_batch.`"]}, {"cell_type": "code", "execution_count": null, "metadata": {"slideshow": {"slide_type": "slide"}}, "outputs": [], "source": ["# Your code here...\n", "from keras.utils import to_categorical\n", "\n", "y_binary = to_categorical(y_train)\n", "\n", "print(f'Shape of training labels: {y_train.shape}')\n", "print(f'Shape of training labels (one-hot): {y_binary.shape}')\n", "\n", "y_train_batch = reshape_to_batches(y_binary, BATCH_SIZE)\n", "\n", "print(f'Shape of training labels after reshaping: {y_train_batch.shape}')\n"]}, {"cell_type": "markdown", "metadata": {"slideshow": {"slide_type": "slide"}}, "source": ["### Create model\n", "\n", "In theory the RNN can read arbitrarily many time-steps, which is one of the reasons it can, theoretically, offer better performance than the CNN for time series. \n", "In practice, however, it is limited by the vanishing gradient problem and the exploding computational requirement implied by taking increasingly many time-steps.\n", "\n", "The cell below imports key Keras layers:\n", "* `Input` and `Dense` which you already know\n", "* `SimpleRNN` and `TimeDistributed` which are helpful for time series"]}, {"cell_type": "code", "execution_count": null, "metadata": {"slideshow": {"slide_type": "slide"}}, "outputs": [], "source": ["# import all dependencies\n", "from keras.layers import Input, Dense, SimpleRNN, TimeDistributed\n", "from keras.models import Model"]}, {"cell_type": "markdown", "metadata": {"slideshow": {"slide_type": "slide"}}, "source": ["Create the input layer (called `inputs`) with appropriate dimensions"]}, {"cell_type": "code", "execution_count": null, "metadata": {"slideshow": {"slide_type": "slide"}}, "outputs": [], "source": ["# add your code here for the input layer\n", "inputs = Input(shape=(BATCH_SIZE, 30))\n"]}, {"cell_type": "markdown", "metadata": {"slideshow": {"slide_type": "slide"}}, "source": ["### Defining the architecture of the RNN\n", "\n", "By default, Keras considers the **many-to-one** architecture, sometimes also known as an _encoder_. \n", "However, we want to perform a prediction at every time step. \n", "Therefore, we make the RNN layer return output for every sequence with `return_sequences=True`.\n", "\n", "The cell below, chained to the `inputs` layer, is an RNN cell.\n", "You should recognize a few things:\n", "\n", "* how many neurons are there? (or what is the dimensionality of the output of that layer?)\n", "* what is the activation function?\n", "* the initializer is the Glorot initializer, centered at zero\n", "* no dropout\n", "\n", "The rest of the parameters don't really matter for now (we will modify some of them later) but feel free to have a look at the [documentation](https://keras.io/layers/recurrent/) for a definition of all the parameters."]}, {"cell_type": "code", "execution_count": null, "metadata": {"slideshow": {"slide_type": "slide"}}, "outputs": [], "source": ["rnn = SimpleRNN(\n", "    64, \n", "    activation='tanh', \n", "    use_bias=True, \n", "    kernel_initializer='glorot_uniform',\n", "    recurrent_initializer='orthogonal', \n", "    bias_initializer='zeros', \n", "    kernel_regularizer=None,\n", "    recurrent_regularizer=None, \n", "    bias_regularizer=None, \n", "    activity_regularizer=None, \n", "    kernel_constraint=None, \n", "    recurrent_constraint=None, \n", "    bias_constraint=None, \n", "    dropout=0.0, \n", "    recurrent_dropout=0.0, \n", "    return_sequences=True, \n", "    return_state=False, \n", "    go_backwards=False, \n", "    stateful=False, \n", "    unroll=False\n", ")(inputs)\n"]}, {"cell_type": "markdown", "metadata": {"slideshow": {"slide_type": "slide"}}, "source": ["The next cell is an output layer with 2 dimensions, given that there are two classes (we're still in the classification context). \n", "\n", "Then, we wrap a model around the whole thing and compile it."]}, {"cell_type": "code", "execution_count": null, "metadata": {"slideshow": {"slide_type": "slide"}}, "outputs": [], "source": ["predictions = TimeDistributed(Dense(2, activation='softmax'))(rnn)\n", "\n", "rnn_model = Model(\n", "    inputs=inputs, \n", "    outputs=predictions\n", ")\n", "\n", "rnn_model.compile(\n", "    optimizer='rmsprop',\n", "    loss='categorical_crossentropy',\n", "    metrics=['accuracy']\n", ")"]}, {"cell_type": "markdown", "metadata": {"slideshow": {"slide_type": "slide"}}, "source": ["Now we're good to fit this for a few epochs and check the performances. "]}, {"cell_type": "code", "execution_count": null, "metadata": {"scrolled": true, "slideshow": {"slide_type": "slide"}}, "outputs": [], "source": ["rnn_model.fit(X_train_s_batch, y_train_batch, epochs=15)"]}, {"cell_type": "markdown", "metadata": {"slideshow": {"slide_type": "slide"}}, "source": ["### Evaluation\n", "\n", "Evaluating the performances of the model.\n", "\n", "- check the shapes of our data, convert as required\n", "- make predictions using `rnn_model.predict(X_test_s_batch)`\n", "- calculate AUC"]}, {"cell_type": "code", "execution_count": null, "metadata": {"slideshow": {"slide_type": "slide"}}, "outputs": [], "source": ["# check the shapes of all relevant objects, reshape if necessary\n", "# first transform the test data into the appropriate shape\n", "print(f'Shape of test features: {X_test_s.shape}')\n", "\n", "X_test_s_batch = reshape_to_batches(X_test_s, BATCH_SIZE)\n", "print(f'Shape of test features after reshaping: {X_test_s_batch.shape}')\n", "\n", "y_binary = to_categorical(y_test)\n", "print(f'Shape of test labels: {y_test.shape}')\n", "print(f'Shape of test labels (one-hot): {y_binary.shape}')\n", "\n", "y_test_batch = reshape_to_batches(y_binary, BATCH_SIZE)\n", "print(f'Shape of test labels after reshaping: {y_test_batch.shape}')"]}, {"cell_type": "code", "execution_count": null, "metadata": {"slideshow": {"slide_type": "slide"}}, "outputs": [], "source": ["# make the prediction\n", "y_pred_rnn = rnn_model.predict(X_test_s_batch)"]}, {"cell_type": "code", "execution_count": null, "metadata": {"slideshow": {"slide_type": "slide"}}, "outputs": [], "source": ["# show the roc auc score\n", "print('AUC:')\n", "print(roc_auc_score(\n", "    convert_3d_to_2d(y_test_batch)[:,1], \n", "    convert_3d_to_2d(y_pred_rnn)[:,1]\n", "))"]}, {"cell_type": "markdown", "metadata": {"slideshow": {"slide_type": "slide"}}, "source": ["### Comparison with the CNN results\n", "\n", "Load the FPR and TPR from the CNN case in (`data/res_cnn.pkl`), show both the AUC of the RNN you've just trained as well as that of the CNN."]}, {"cell_type": "code", "execution_count": null, "metadata": {"slideshow": {"slide_type": "slide"}}, "outputs": [], "source": ["# load\n", "import pickle\n", "\n", "fpr_cnn, tpr_cnn, thresh_cnn, y_pred_cnn = pickle.load(\n", "    open(\"data/res_cnn.pkl\", \"rb\"))\n", "fpr_rnn, tpr_rnn, thresh_rnn = roc_curve(\n", "    convert_3d_to_2d(y_test_batch)[:, 1], convert_3d_to_2d(y_pred_rnn)[:, 1])"]}, {"cell_type": "code", "execution_count": null, "metadata": {"slideshow": {"slide_type": "slide"}}, "outputs": [], "source": ["# show the AUC for the CNN and the RNN\n", "plt.figure(figsize=(8, 6))\n", "lw = 2\n", "plt.plot(fpr_cnn, tpr_cnn, color='C0',\n", "         lw=lw, label='CNN')\n", "plt.plot(fpr_rnn, tpr_rnn, color='C1',\n", "         lw=lw, label='RNN')\n", "plt.plot([0, 1], [0, 1], color='navy', lw=lw, ls='--')\n", "plt.xlim([0, 1])\n", "plt.ylim([0, 1.05])\n", "plt.xlabel('FPR', fontsize=12)\n", "plt.ylabel('TPR', fontsize=12)\n", "plt.legend(fontsize=12)\n", "plt.show()\n"]}, {"cell_type": "markdown", "metadata": {"slideshow": {"slide_type": "slide"}}, "source": ["As you can observe, the RNN is better than the CNN here (the corresponding curve is mostly or completely above). \n", "AUC offers a nice way to compare between different classification models.\n", "\n", "**Note**: remain careful though, the AUC puts emphasis on the *accuracy* but, as you know, in this case we may care more about fraud *recall*. \n", "Don't forget to also check the confusion matrices etc."]}, {"cell_type": "markdown", "metadata": {"slideshow": {"slide_type": "slide"}}, "source": ["## LSTM\n", "\n", "One of the best parts of using Keras' functional API is that we can easily reuse components. Let's replace the vanilla RNN with an LSTM.\n", "Again, you should recognise a few things, in fact pretty much everything is similar to the `SimpleRNN` you used before. "]}, {"cell_type": "code", "execution_count": null, "metadata": {"slideshow": {"slide_type": "slide"}}, "outputs": [], "source": ["from keras.layers import LSTM\n", "\n", "# the implementation parameter determines whether your hardware is cpu (1) or gpu (2)\n", "lstm = LSTM(\n", "    64, \n", "    activation='tanh', \n", "    recurrent_activation='hard_sigmoid', \n", "    use_bias=True, \n", "    kernel_initializer='glorot_uniform', \n", "    recurrent_initializer='orthogonal', \n", "    bias_initializer='zeros', \n", "    unit_forget_bias=True, \n", "    kernel_regularizer=None, \n", "    recurrent_regularizer=None, \n", "    bias_regularizer=None, \n", "    activity_regularizer=None, \n", "    kernel_constraint=None, \n", "    recurrent_constraint=None, \n", "    bias_constraint=None, \n", "    dropout=0.0, \n", "    recurrent_dropout=0.0, \n", "    implementation=1,      # CPU or GPU\n", "    return_sequences=True, \n", "    return_state=False, \n", "    go_backwards=False, \n", "    stateful=False,\n", "    unroll=False\n", ")(inputs)\n", "\n", "# finally we give a 2 dimensional softmax output layer\n", "predictions = TimeDistributed(Dense(2, activation='softmax'))(lstm)\n", "\n", "lstm_model = Model(\n", "    inputs=inputs, \n", "    outputs=predictions\n", ")\n", "\n", "lstm_model.compile(\n", "    optimizer='rmsprop',\n", "    loss='categorical_crossentropy',\n", "    metrics=['accuracy']\n", ")"]}, {"cell_type": "code", "execution_count": null, "metadata": {"scrolled": true, "slideshow": {"slide_type": "slide"}}, "outputs": [], "source": ["# add your code to fit the model\n", "lstm_model.fit(X_train_s_batch, y_train_batch, epochs=15)\n"]}, {"cell_type": "markdown", "metadata": {"slideshow": {"slide_type": "slide"}}, "source": ["### Evaluate the quality of the LSTM classifier\n", "\n", "Compare the LSTM to both the RNN and the CNN."]}, {"cell_type": "code", "execution_count": null, "metadata": {"slideshow": {"slide_type": "slide"}}, "outputs": [], "source": ["# add your code to compare models\n", "y_pred_lstm = lstm_model.predict(X_test_s_batch)\n", "\n", "fpr_lstm, tpr_lstm, thresh_lstm = roc_curve(\n", "    convert_3d_to_2d(y_test_batch)[:, 1], \n", "    convert_3d_to_2d(y_pred_lstm)[:, 1]\n", ")\n", "\n", "plt.figure(figsize=(8, 6))\n", "lw = 2\n", "plt.plot(\n", "    fpr_cnn,\n", "    tpr_cnn,\n", "    color='C0',\n", "    lw=lw,\n", "    label='CNN'\n", ")\n", "plt.plot(\n", "    fpr_rnn,\n", "    tpr_rnn,\n", "    color='C1',\n", "    lw=lw,\n", "    label='RNN'\n", ")\n", "plt.plot(\n", "    fpr_lstm,\n", "    tpr_lstm,\n", "    color='C2',\n", "    lw=lw,\n", "    label='LSTM'\n", ")\n", "plt.plot([0, 1], [0, 1], color='navy', lw=lw, ls='--')\n", "plt.xlim([0, 1])\n", "plt.ylim([0, 1.05])\n", "plt.xlabel('FPR', fontsize=12)\n", "plt.ylabel('TPR', fontsize=12)\n", "plt.legend(fontsize=12)\n", "\n", "print(f\"CNN  AUC: {auc(fpr_cnn, tpr_cnn):.4f}\")\n", "print(f\"RNN  AUC: {auc(fpr_rnn, tpr_rnn):.4f}\")\n", "print(f\"LSTM AUC: {auc(fpr_lstm, tpr_lstm):.4f}\")\n", "plt.show()\n"]}, {"cell_type": "markdown", "metadata": {"slideshow": {"slide_type": "slide"}}, "source": ["## LSTM vs GRU\n", "\n", "The last one we can test is the GRU. "]}, {"cell_type": "code", "execution_count": null, "metadata": {"slideshow": {"slide_type": "slide"}}, "outputs": [], "source": ["from keras.layers import GRU\n", "\n", "gru = GRU(\n", "    64, \n", "    activation='tanh', \n", "    recurrent_activation='hard_sigmoid',\n", "    use_bias=True, \n", "    kernel_initializer='glorot_uniform',\n", "    recurrent_initializer='orthogonal', \n", "    bias_initializer='zeros',\n", "    kernel_regularizer=None, \n", "    recurrent_regularizer=None, \n", "    bias_regularizer=None,\n", "    activity_regularizer=None, \n", "    kernel_constraint=None, \n", "    recurrent_constraint=None,\n", "    bias_constraint=None, \n", "    dropout=0.0, \n", "    recurrent_dropout=0.0, \n", "    implementation=1,\n", "    return_sequences=True, \n", "    return_state=False, \n", "    go_backwards=False, \n", "    stateful=False, \n", "    unroll=False\n", ")(inputs)\n", "\n", "# output layer, as per usual\n", "predictions = TimeDistributed(Dense(2, activation='softmax'))(gru)"]}, {"cell_type": "code", "execution_count": null, "metadata": {"scrolled": true, "slideshow": {"slide_type": "slide"}}, "outputs": [], "source": ["# model compilation and fitting\n", "gru_model = Model(\n", "    inputs=inputs,\n", "    outputs=predictions\n", ")\n", "gru_model.compile(\n", "    optimizer='rmsprop',\n", "    loss='categorical_crossentropy',\n", "    metrics=['accuracy']\n", ")\n", "gru_model.fit(X_train_s_batch, y_train_batch, epochs=15)"]}, {"cell_type": "markdown", "metadata": {"slideshow": {"slide_type": "slide"}}, "source": ["### Evaluation"]}, {"cell_type": "code", "execution_count": null, "metadata": {"slideshow": {"slide_type": "slide"}}, "outputs": [], "source": ["# add your code to compare models\n", "y_pred_gru = gru_model.predict(X_test_s_batch)\n", "\n", "fpr_gru, tpr_gru, thresh_gru = roc_curve(convert_3d_to_2d(y_test_batch)[:, 1], \n", "                                         convert_3d_to_2d(y_pred_gru)[:, 1])\n", "\n", "plt.figure(figsize=(8, 6))\n", "lw = 2\n", "plt.plot(\n", "    fpr_cnn,\n", "    tpr_cnn,\n", "    color='C0',\n", "    lw=lw,\n", "    label='CNN'\n", ")\n", "plt.plot(\n", "    fpr_rnn,\n", "    tpr_rnn,\n", "    color='C1',\n", "    lw=lw,\n", "    label='RNN'\n", ")\n", "plt.plot(\n", "    fpr_lstm,\n", "    tpr_lstm,\n", "    color='C2',\n", "    lw=lw,\n", "    label='LSTM'\n", ")\n", "plt.plot(\n", "    fpr_gru,\n", "    tpr_gru,\n", "    color='C3',\n", "    lw=lw,\n", "    label='GRU'\n", ")\n", "plt.plot([0, 1], [0, 1], color='navy', lw=lw, ls='--')\n", "plt.xlim([0, 1])\n", "plt.ylim([0, 1.05])\n", "plt.xlabel('FPR', fontsize=12)\n", "plt.ylabel('TPR', fontsize=12)\n", "plt.legend(fontsize=12)\n", "\n", "print(f\"CNN  AUC: {auc(fpr_cnn, tpr_cnn):.4f}\")\n", "print(f\"RNN  AUC: {auc(fpr_rnn, tpr_rnn):.4f}\")\n", "print(f\"LSTM AUC: {auc(fpr_lstm, tpr_lstm):.4f}\")\n", "print(f\"GRU  AUC: {auc(fpr_gru, tpr_gru):.4f}\")\n"]}, {"cell_type": "markdown", "metadata": {"slideshow": {"slide_type": "slide"}}, "source": ["## Stacking: combine NNs as lego blocks\n", "\n", "Just as with CNNs, RNN units can be stacked on top of each other to form a more involved model. \n", "Since the weights are shared in each RNN stack (layer), the hypothesis is that every stack forms both new features and a different time-scale at which it operates. \n", "\n", "Try to build two LSTM layers with the same settings as before, stack one after the other and test the whole lot. "]}, {"cell_type": "code", "execution_count": null, "metadata": {"slideshow": {"slide_type": "slide"}}, "outputs": [], "source": ["# add your code here\n", "lstm1 = LSTM(64, activation='tanh', recurrent_activation='hard_sigmoid', use_bias=True, \n", "            kernel_initializer='glorot_uniform', recurrent_initializer='orthogonal', \n", "            bias_initializer='zeros', unit_forget_bias=True, kernel_regularizer=None, \n", "            recurrent_regularizer=None, bias_regularizer=None, activity_regularizer=None, \n", "            kernel_constraint=None, recurrent_constraint=None, bias_constraint=None, dropout=0.0, \n", "            recurrent_dropout=0.0, implementation=1, return_sequences=True, return_state=False, \n", "            go_backwards=False, stateful=False, unroll=False)(inputs)\n", "\n", "lstm2 = LSTM(64, activation='tanh', recurrent_activation='hard_sigmoid', use_bias=True, \n", "            kernel_initializer='glorot_uniform', recurrent_initializer='orthogonal', \n", "            bias_initializer='zeros', unit_forget_bias=True, kernel_regularizer=None, \n", "            recurrent_regularizer=None, bias_regularizer=None, activity_regularizer=None, \n", "            kernel_constraint=None, recurrent_constraint=None, bias_constraint=None, dropout=0.0, \n", "            recurrent_dropout=0.0, implementation=1, return_sequences=True, return_state=False, \n", "            go_backwards=False, stateful=False, unroll=False)(lstm1)\n", "\n", "predictions = TimeDistributed(Dense(2, activation='softmax'))(lstm2)\n", "lstm64x64_model = Model(\n", "    inputs=inputs,\n", "    outputs=predictions\n", ")\n", "lstm64x64_model.compile(\n", "    optimizer='rmsprop',\n", "    loss='categorical_crossentropy',\n", "    metrics=['accuracy']\n", ")\n", "lstm64x64_model.fit(X_train_s_batch, y_train_batch, epochs=15)\n", "y_pred_lstm64x64 = lstm64x64_model.predict(X_test_s_batch)\n"]}, {"cell_type": "markdown", "metadata": {"slideshow": {"slide_type": "slide"}}, "source": ["Observe that the training is now a bit slower, you have twice as many parameters after all... \n", "\n", "Check the performances as compared with the 1-layer LSTM."]}, {"cell_type": "code", "execution_count": null, "metadata": {"scrolled": true, "slideshow": {"slide_type": "slide"}}, "outputs": [], "source": ["# add your code to compare models\n", "fpr_lstm64x64, tpr_lstm64x64, thresh_lstm64x64 = roc_curve(\n", "    convert_3d_to_2d(y_test_batch)[:, 1],\n", "    convert_3d_to_2d(y_pred_lstm64x64)[:, 1]\n", ")\n", "\n", "plt.figure(figsize=(8, 6))\n", "lw = 2\n", "plt.plot(\n", "    fpr_lstm,\n", "    tpr_lstm,\n", "    color='C4',\n", "    lw=lw,\n", "    label='LSTM 64'\n", ")\n", "plt.plot(\n", "    fpr_lstm64x64,\n", "    tpr_lstm64x64,\n", "    color='C5',\n", "    lw=lw,\n", "    label='LSTM 64 x 64'\n", ")\n", "plt.plot([0, 1], [0, 1], color='navy', lw=lw, ls='--')\n", "plt.xlim([0, 1])\n", "plt.ylim([0, 1.05])\n", "plt.xlabel('FPR', fontsize=12)\n", "plt.ylabel('TPR', fontsize=12)\n", "plt.legend(fontsize=12)\n", "\n", "print(f\"LSTM 64      AUC: {auc(fpr_lstm, tpr_lstm):.4f}\")\n", "print(f\"LSTM 64 x 64 AUC: {auc(fpr_lstm64x64, tpr_lstm64x64):.4f}\")\n"]}, {"cell_type": "markdown", "metadata": {"slideshow": {"slide_type": "slide"}}, "source": ["So that's worse. \n", "Quite likely we have started to overfit...\n", "\n", "There are two ways to go about countering possible overfitting in the hope that a more complex model might lead to better performances (which is not necessarily true):\n", "1. decrease the number of parameters\n", "2. introduce regularisation\n", "\n", "Let's start by reducing the number of parameters from 64 to 32, do exactly the same as before but with LSTMs with only 32 neurons per layer. "]}, {"cell_type": "code", "execution_count": null, "metadata": {"slideshow": {"slide_type": "slide"}}, "outputs": [], "source": ["# add your code here\n", "lstm1 = LSTM(32, activation='tanh', recurrent_activation='hard_sigmoid', use_bias=True, \n", "            kernel_initializer='glorot_uniform', recurrent_initializer='orthogonal', \n", "            bias_initializer='zeros', unit_forget_bias=True, kernel_regularizer=None, \n", "            recurrent_regularizer=None, bias_regularizer=None, activity_regularizer=None, \n", "            kernel_constraint=None, recurrent_constraint=None, bias_constraint=None, dropout=0.0, \n", "            recurrent_dropout=0.0, implementation=1, return_sequences=True, return_state=False, \n", "            go_backwards=False, stateful=False, unroll=False)(inputs)\n", "\n", "lstm2 = LSTM(32, activation='tanh', recurrent_activation='hard_sigmoid', use_bias=True, \n", "            kernel_initializer='glorot_uniform', recurrent_initializer='orthogonal', \n", "            bias_initializer='zeros', unit_forget_bias=True, kernel_regularizer=None, \n", "            recurrent_regularizer=None, bias_regularizer=None, activity_regularizer=None, \n", "            kernel_constraint=None, recurrent_constraint=None, bias_constraint=None, dropout=0.0, \n", "            recurrent_dropout=0.0, implementation=1, return_sequences=True, return_state=False, \n", "            go_backwards=False, stateful=False, unroll=False)(lstm1)\n", "\n", "predictions = TimeDistributed(Dense(2, activation='softmax'))(lstm2)\n", "lstm32x32_model = Model(\n", "    inputs=inputs,\n", "    outputs=predictions\n", ")\n", "lstm32x32_model.compile(\n", "    optimizer='rmsprop',\n", "    loss='categorical_crossentropy',\n", "    metrics=['accuracy']\n", ")\n", "\n", "lstm32x32_model.fit(X_train_s_batch, y_train_batch, epochs=15)\n", "y_pred_lstm32x32 = lstm32x32_model.predict(X_test_s_batch)\n"]}, {"cell_type": "code", "execution_count": null, "metadata": {"scrolled": true, "slideshow": {"slide_type": "slide"}}, "outputs": [], "source": ["# add your code to compare models\n", "fpr_lstm32x32, tpr_lstm32x32, thresh_lstm32x32 = roc_curve(\n", "    convert_3d_to_2d(y_test_batch)[:, 1],\n", "    convert_3d_to_2d(y_pred_lstm32x32)[:, 1]\n", ")\n", "\n", "plt.figure(figsize=(8, 6))\n", "lw = 2\n", "plt.plot(\n", "    fpr_lstm,\n", "    tpr_lstm,\n", "    color='C4',\n", "    lw=lw,\n", "    label='LSTM 64'\n", ")\n", "plt.plot(\n", "    fpr_lstm64x64,\n", "    tpr_lstm64x64,\n", "    color='C5',\n", "    lw=lw,\n", "    label='LSTM 64 x 64'\n", ")\n", "plt.plot(\n", "    fpr_lstm32x32,\n", "    tpr_lstm32x32,\n", "    color='C6',\n", "    lw=lw,\n", "    label='LSTM 32 x 32'\n", ")\n", "plt.plot([0, 1], [0, 1], color='navy', lw=lw, ls='--')\n", "plt.xlim([0, 1])\n", "plt.ylim([0, 1.05])\n", "plt.xlabel('FPR', fontsize=12)\n", "plt.ylabel('TPR', fontsize=12)\n", "plt.legend(fontsize=12)\n", "\n", "print(f\"LSTM 64      AUC: {auc(fpr_lstm, tpr_lstm):.4f}\")\n", "print(f\"LSTM 64 x 64 AUC: {auc(fpr_lstm64x64, tpr_lstm64x64):.4f}\")\n", "print(f\"LSTM 32 x 32 AUC: {auc(fpr_lstm32x32, tpr_lstm32x32):.4f}\")\n"]}, {"cell_type": "markdown", "metadata": {"slideshow": {"slide_type": "slide"}}, "source": ["Ok, that's better. \n", "\n", "You may get a slightly different result but it should be approximately:\n", "\n", "* AUC LSTM 64    = 0.9734\n", "* AUC LSTM 64x64 = 0.9573 (-1.6 %)\n", "* AUC LSTM 32x32 = 0.9739 (+0.05 %)\n", "\n", "Of course, to be complete, you should also look at the fraud recall as we've already mentioned before."]}]}