{"cells": [{"cell_type": "markdown", "metadata": {"slideshow": {"slide_type": "slide"}}, "source": ["# Introduction to ensemble methods\n", "\n", "In this practical, you will construct your own bagging ensemble, to boost performance on a binary classification problem.\n", "\n", "\n", "## The problem\n", "\n", "Users of your service sometimes close their accounts, even though they have been with you for a while. It would be useful if you could predict which ones are likely to do this, before it happens, so you can take action to retain their custom.\n", "\n", "You have access to 20 different features for each user, based on data such as how often they log in, how many purchases they make, etc. The aim is to see if you can predict whether a user will end up closing their account or not.\n", "\n", "## Getting started\n", "\n", "First, load the data from `account_data.csv` using `pandas` into a DataFrame called `data`. \n", "\n", "Find out how many users left the service by examining the `closed_account` column. \n", "\n", "*Hint: use the `.value_counts()` method*"]}, {"cell_type": "code", "execution_count": 3, "metadata": {"slideshow": {"slide_type": "slide"}}, "outputs": [], "source": ["import pandas as pd\n", "\n", "# Your code here...\n", "data = pd.read_csv('data/account_data.csv')\n", "\n", "data['closed_account'].value_counts()"]}, {"cell_type": "code", "execution_count": 4, "metadata": {}, "outputs": [], "source": ["data.head()"]}, {"cell_type": "markdown", "metadata": {"slideshow": {"slide_type": "slide"}}, "source": ["## Setting up for classification\n", "\n", "Before proceeding, we will split the data into training and testing subsets.\n", "\n", "Create two variables, `X` and `y`, from the `data` DataFrame.\n", "\n", "`X` should be all the columns that you want to use in your prediction (ie. all except for `closed_account`)\n", "\n", "`y` should be the column that you are trying to predict (ie. `closed_account`)\n", "\n", "These are the conventional variable names used in machine learning to represent your predicting features (`X`) and the values you are trying to predict (`y`)."]}, {"cell_type": "code", "execution_count": 5, "metadata": {"slideshow": {"slide_type": "slide"}}, "outputs": [], "source": ["# Your code here...\n", "X = data.drop(columns=['closed_account'])\n", "y = data['closed_account']"]}, {"cell_type": "markdown", "metadata": {"slideshow": {"slide_type": "slide"}}, "source": ["Models will have access to the training set in order to learn, but we will evaluate them on the unseen test set.\n", "\n", "Use `train_test_split` from `sklearn.model_selection` to split the data up. \n", "\n", "This function takes your `X` and `y` (our 20 monthly data points, and the closed/not closed label) and splits them up. It returns four lists - one `X` for each of train/test and the same for `y`.\n", "\n", "The default gives a ratio of 3:1 train/test split.\n", "\n", "Call the new variables `X_train`, `X_test`, `y_train`, and `y_test`.\n", "\n", "(Set `random_state` to `5`, so that results are the same every time!)"]}, {"cell_type": "code", "execution_count": 6, "metadata": {"slideshow": {"slide_type": "slide"}}, "outputs": [], "source": ["from sklearn.model_selection import train_test_split\n", "\n", "# Your code here...\n", "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=5)"]}, {"cell_type": "markdown", "metadata": {"slideshow": {"slide_type": "slide"}}, "source": ["## Single model performance\n", "\n", "Before trying an ensemble, we need some baselines in order to determine whether the ensemble method actually improved anything.\n", "\n", "We will use a simple Naive Bayes classifier here with default parameters.\n", "\n", "Import the required class and instantiate it with the variable name `model`.\n"]}, {"cell_type": "code", "execution_count": 7, "metadata": {"slideshow": {"slide_type": "slide"}}, "outputs": [], "source": ["from sklearn.naive_bayes import GaussianNB\n", "\n", "# Your code here...\n", "model = GaussianNB()"]}, {"cell_type": "code", "execution_count": 8, "metadata": {}, "outputs": [], "source": ["model.fit(X_train, y_train)"]}, {"cell_type": "code", "execution_count": 9, "metadata": {}, "outputs": [], "source": ["model.score(X_train, y_train)"]}, {"cell_type": "code", "execution_count": 10, "metadata": {}, "outputs": [], "source": ["y_train_pred = model.predict(X_train)"]}, {"cell_type": "markdown", "metadata": {"slideshow": {"slide_type": "slide"}}, "source": ["Use the `.fit()` method of the model to train it on the training subset of the data.\n", "\n", "Use the `.score()` method the same way, using the same data, to see how well it performs on the data it learned from.\n", "\n", "Use `model.predict()` to generate predictions for `X_train` and compare these predictions to the ground truth (`y_train`) using a classification report."]}, {"cell_type": "code", "execution_count": 12, "metadata": {"slideshow": {"slide_type": "slide"}}, "outputs": [], "source": ["from sklearn.metrics import classification_report\n", "\n", "# Your code here...\n", "print(classification_report(y_train, y_train_pred))"]}, {"cell_type": "markdown", "metadata": {"slideshow": {"slide_type": "slide"}}, "source": ["Repeat the above scoring process but now use the unseen test data.\n", "\n", "Do you expect accuracy to change? If so, in what direction?\n", "\n", "What are your thoughts on how well the model performs on the two classes?"]}, {"cell_type": "code", "execution_count": 13, "metadata": {"slideshow": {"slide_type": "slide"}}, "outputs": [], "source": ["# Your code here...\n", "y_pred = model.predict(X_test)"]}, {"cell_type": "code", "execution_count": 14, "metadata": {}, "outputs": [], "source": ["print(classification_report(y_test, y_pred))"]}, {"cell_type": "markdown", "metadata": {"slideshow": {"slide_type": "slide"}}, "source": ["## Bagging ensemble\n", "\n", "Now let's see what effect a simple bagging ensemble has.\n", "\n", "`sklearn` has a useful utility class that will handle this for us: `sklearn.ensemble.BaggingClassifier`\n", "\n", "This has several parameters which can be tuned but the main ones are:\n", "\n", "`estimator` - the model to use\n", "\n", "`n_estimators` - how many models to use. Default is 10.\n", "\n", "`random_state` - ensures the same results every time\n", "\n", "Create a bagging classifier named `ensemble`, using `GaussianNB()` as the `estimator`. Keep `n_estimators` at 10 and set `random_state` to 5."]}, {"cell_type": "code", "execution_count": 18, "metadata": {"slideshow": {"slide_type": "slide"}}, "outputs": [], "source": ["from sklearn.ensemble import BaggingClassifier\n", "\n", "# Your code here...\n", "ensemble = BaggingClassifier(estimator=GaussianNB(),\n", "                             n_estimators=10,\n", "                             random_state=5\n", "                            )"]}, {"cell_type": "markdown", "metadata": {"slideshow": {"slide_type": "slide"}}, "source": ["Once you have created this meta-model, it works exactly the same way as any model in `sklearn` - it has  methods like `.fit()` and `.score()` and `.predict()`.\n", "\n", "Repeat the training/scoring/classification report process from the single model approach you did previously.\n", "\n", "Train only on the training data and test only on the test data.\n", "\n", "What do you observe now?"]}, {"cell_type": "code", "execution_count": 19, "metadata": {}, "outputs": [], "source": ["ensemble.fit(X_train, y_train)"]}, {"cell_type": "code", "execution_count": 27, "metadata": {}, "outputs": [], "source": ["ensemble.score(X_test, y_test)"]}, {"cell_type": "code", "execution_count": 23, "metadata": {}, "outputs": [], "source": ["y_train_pred_ensemble = ensemble.predict(X_train)"]}, {"cell_type": "code", "execution_count": 25, "metadata": {}, "outputs": [], "source": ["print(classification_report(y_train, y_train_pred_ensemble))"]}, {"cell_type": "code", "execution_count": 24, "metadata": {}, "outputs": [], "source": ["y_pred_ensemble = ensemble.predict(X_test)"]}, {"cell_type": "code", "execution_count": 26, "metadata": {}, "outputs": [], "source": ["print(classification_report(y_test, y_pred_ensemble))"]}, {"cell_type": "code", "execution_count": null, "metadata": {"slideshow": {"slide_type": "slide"}}, "outputs": [], "source": ["# Your code here...\n"]}, {"cell_type": "markdown", "metadata": {"slideshow": {"slide_type": "slide"}}, "source": ["## Conclusions\n", "\n", "Using an ensemble of methods improved performance in a binary classification task by a good margin, though performance was still generally quite low.\n", "\n", "This may be because the signal to noise ratio in the data is low (we have used synthetic data), meaning the model needs to make predictions with very little information. Even so, what could you investigate in order to improve performance on this task?"]}, {"cell_type": "code", "execution_count": null, "metadata": {"slideshow": {"slide_type": "slide"}}, "outputs": [], "source": ["# Your code below\n"]}], "metadata": {"kernelspec": {"display_name": "Python 3 (ipykernel)", "language": "python", "name": "python3"}, "language_info": {"codemirror_mode": {"name": "ipython", "version": 3}, "file_extension": ".py", "mimetype": "text/x-python", "name": "python", "nbconvert_exporter": "python", "pygments_lexer": "ipython3", "version": "3.11.9"}}, "nbformat": 4, "nbformat_minor": 4}